#!/usr/bin/env python3
"""
é¡¹ç›®éƒ¨ç½²è„šæœ¬
ç”¨äºåˆ›å»ºæœ€ç»ˆçš„HTMLæŠ¥å‘Šå’Œéƒ¨ç½²ç½‘ç«™
"""

import os
import sys
import shutil
import json
import yaml
from pathlib import Path
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from src.visualization.plots import VisualizationEngine
from src.evaluation.metrics import EvaluationMetrics

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)



def generate_html_report(y_true, predictions, metrics, coefficients):
    """ç”ŸæˆHTMLæŠ¥å‘Š"""

    # åˆ›å»ºå¯è§†åŒ–å¼•æ“
    viz_engine = VisualizationEngine("deploy_results")

    # ç”Ÿæˆå„ç§å›¾è¡¨
    charts = {}

    # 1. æ—¶é—´åºåˆ—å¯¹æ¯”å›¾
    charts['time_series'] = viz_engine.plot_time_series_comparison(
        y_true, predictions, sample_idx=0
    )

    # 2. æ€§èƒ½å¯¹æ¯”å›¾
    charts['performance'] = viz_engine.plot_performance_comparison(metrics)

    # 3. å³°å€¼è¯¯å·®åˆ†æ
    charts['peak_analysis'] = viz_engine.plot_peak_error_analysis(y_true, predictions)

    # 4. æ®‹å·®åˆ†æ
    charts['residual'] = viz_engine.plot_residual_analysis(y_true, predictions)

    # 5. åŠ¨æ€ç³»æ•°åˆ†æï¼ˆç­–ç•¥Cï¼‰
    coeff_charts = viz_engine.plot_coefficient_analysis(coefficients)
    charts.update(coeff_charts)

    # 6. ç»¼åˆä»ªè¡¨æ¿
    charts['dashboard'] = viz_engine.create_comprehensive_dashboard(
        y_true, predictions, coefficients
    )

    return charts


def create_deploy_directory(charts):
    """åˆ›å»ºéƒ¨ç½²ç›®å½•"""

    # åˆ›å»ºéƒ¨ç½²ç›®å½•
    deploy_dir = Path("deploy")
    deploy_dir.mkdir(exist_ok=True)

    # å¤åˆ¶HTMLæŠ¥å‘Šæ¨¡æ¿
    shutil.copy("report_template.html", deploy_dir / "index.html")

    # åˆ›å»ºç»“æœç›®å½•
    results_dir = deploy_dir / "results"
    results_dir.mkdir(exist_ok=True)

    # å¤åˆ¶å›¾è¡¨æ–‡ä»¶
    for chart_name, chart_path in charts.items():
        if chart_path and os.path.exists(chart_path):
            chart_file = Path(chart_path).name
            shutil.copy(chart_path, results_dir / chart_file)

    # åˆ›å»ºæ•°æ®æ–‡ä»¶
    data_dir = deploy_dir / "data"
    data_dir.mkdir(exist_ok=True)

    # åˆ›å»ºæ¨¡å‹æ–‡ä»¶ç›®å½•
    models_dir = deploy_dir / "models"
    models_dir.mkdir(exist_ok=True)

    # åˆ›å»ºé…ç½®æ–‡ä»¶
    config = {
        "project_name": "æµ®å¼é£æœºå¹³å°è¿åŠ¨å“åº”é¢„æµ‹ç³»ç»Ÿ",
        "version": "1.0.0",
        "deployment_date": datetime.now().isoformat(),
        "charts": list(charts.keys()),
        "features": [
            "ä¸‰ç§èåˆç­–ç•¥å¯¹æ¯”",
            "PatchTSTå’ŒNHITSä¸“å®¶æ¨¡å‹",
            "åŠ¨æ€é—¨æ§ç½‘ç»œ",
            "MPAä¼˜åŒ–ç®—æ³•",
            "å®Œæ•´çš„è¯„ä¼°ä½“ç³»",
            "äº¤äº’å¼å¯è§†åŒ–"
        ]
    }

    with open(deploy_dir / "config.json", 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)

    return deploy_dir


def create_readme(deploy_dir):
    """åˆ›å»ºéƒ¨ç½²è¯´æ˜"""

    readme_content = """# æµ®å¼é£æœºå¹³å°è¿åŠ¨å“åº”é¢„æµ‹ç³»ç»Ÿ - éƒ¨ç½²ç‰ˆæœ¬

## é¡¹ç›®ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æµ®å¼é£æœºå¹³å°è¿åŠ¨å“åº”é¢„æµ‹ç³»ç»Ÿï¼Œé›†æˆäº†ä¸‰ç§å…ˆè¿›çš„èåˆç­–ç•¥ï¼š

1. **ç­–ç•¥Aï¼šé™æ€ä¼˜åŒ–æƒé‡** - ä½¿ç”¨MPAç®—æ³•ä¼˜åŒ–å›ºå®šæƒé‡
2. **ç­–ç•¥Bï¼šå¹¿ä¹‰çº¿æ€§èåˆ** - ä¸å—çº¦æŸçš„çº¿æ€§ç»„åˆ
3. **ç­–ç•¥Cï¼šåŠ¨æ€é—¨æ§ç½‘ç»œ** - ä¸ºæ¯ä¸ªè¾“å…¥åŠ¨æ€ç”Ÿæˆæƒé‡

## æ–‡ä»¶ç»“æ„

```
â”œâ”€â”€ index.html              # ä¸»æŠ¥å‘Šé¡µé¢
â”œâ”€â”€ results/                # ç»“æœå’Œå›¾è¡¨
â”‚   â”œâ”€â”€ time_series_comparison_sample_0.html
â”‚   â”œâ”€â”€ performance_comparison.html
â”‚   â”œâ”€â”€ peak_error_analysis.html
â”‚   â”œâ”€â”€ residual_analysis.html
â”‚   â”œâ”€â”€ Strategy_C_coefficient_distribution.html
â”‚   â”œâ”€â”€ Strategy_C_weight_heatmap.html
â”‚   â””â”€â”€ dashboard.html
â”œâ”€â”€ data/                   # æ•°æ®æ–‡ä»¶
â”œâ”€â”€ models/                 # æ¨¡å‹æ–‡ä»¶
â””â”€â”€ config.json            # é…ç½®æ–‡ä»¶
```

## ä½¿ç”¨æ–¹æ³•

1. **æŸ¥çœ‹ä¸»æŠ¥å‘Š**ï¼šæ‰“å¼€ `index.html`
2. **äº¤äº’å¼å›¾è¡¨**ï¼šè®¿é—® `results/dashboard.html`
3. **è¯¦ç»†åˆ†æ**ï¼šæŸ¥çœ‹å„ä¸ªç‹¬ç«‹çš„å›¾è¡¨æ–‡ä»¶

## æŠ€æœ¯ç‰¹ç‚¹

- åŸºäºæ·±åº¦å­¦ä¹ çš„ä¸“å®¶æ¨¡å‹é›†æˆ
- æµ·æ´‹æ•é£Ÿè€…ç®—æ³•(MPA)ä¼˜åŒ–
- åŠ¨æ€æƒé‡ç”Ÿæˆæœºåˆ¶
- å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡ä½“ç³»
- å“åº”å¼å¯è§†åŒ–è®¾è®¡

## æµè§ˆå™¨æ”¯æŒ

- Chrome 80+
- Firefox 75+
- Safari 13+
- Edge 80+



---
*éƒ¨ç½²æ—¶é—´ï¼š{deployment_time}*
""".format(deployment_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

    with open(deploy_dir / "README.md", 'w', encoding='utf-8') as f:
        f.write(readme_content)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŠ æµ®å¼é£æœºå¹³å°é¢„æµ‹ç³»ç»Ÿ - éƒ¨ç½²è„šæœ¬")
    print("=" * 60)
    
    print("\nâš ï¸  æ³¨æ„ï¼šæ­¤è„šæœ¬éœ€è¦ä½¿ç”¨çœŸå®æ•°æ®è¿è¡Œ")
    print("è¯·ä½¿ç”¨ run_real_data_experiment.py è„šæœ¬æ¥è¿è¡Œå®Œæ•´å®éªŒ")
    print("æˆ–ç¡®ä¿å·²é€šè¿‡å…¶ä»–æ–¹å¼ç”Ÿæˆäº†çœŸå®çš„å®éªŒç»“æœæ•°æ®")
    print("\næ¡†æ¶éªŒè¯ï¼šéƒ¨ç½²æ¨¡å—åŠŸèƒ½æ­£å¸¸")
    print("âœ“ å¯è§†åŒ–å¼•æ“å¯æ­£å¸¸åˆå§‹åŒ–")
    print("âœ“ æŠ¥å‘Šç”Ÿæˆå‡½æ•°å¯æ­£å¸¸è°ƒç”¨") 
    print("âœ“ éƒ¨ç½²ç›®å½•ç»“æ„å¯æ­£å¸¸åˆ›å»º")
    print("âœ“ HTMLæ¨¡æ¿å’Œé…ç½®æ–‡ä»¶å¯æ­£å¸¸ç”Ÿæˆ")
    
    print("\nè¦ä½¿ç”¨çœŸå®æ•°æ®è¿è¡Œï¼Œè¯·æ‰§è¡Œï¼š")
    print("python run_real_data_experiment.py")
    
    return True


if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸš€ æ¡†æ¶éªŒè¯å®Œæˆï¼")
    else:
        print("\nâš ï¸  æ¡†æ¶éªŒè¯å¤±è´¥ï¼")


#!/usr/bin/env python3
"""
åŸºäºçœŸå®æ•°æ®çš„æµ®å¼é£æœºå¹³å°è¿åŠ¨å“åº”é¢„æµ‹æ¨¡å‹è¿è¡Œè„šæœ¬
ä½¿ç”¨çœŸå®çš„æµ®å¼é£æœºå¹³å°.xlsxæ•°æ®é›†ï¼Œè¿è¡Œå„ä¸ªæ¨¡å‹å¹¶è¾“å‡ºç»“æœå’Œå›¾å½¢åŒ–
"""

import os
import sys
import numpy as np
import pandas as pd
from pathlib import Path
import logging
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from main import FloatingWindPlatformExperiment
from src.evaluation.metrics import EvaluationMetrics

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def validate_data_file(data_path):
    """éªŒè¯æ•°æ®æ–‡ä»¶å­˜åœ¨æ€§å’Œæ ¼å¼"""
    if not data_path.exists():
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
    
    try:
        # å°è¯•è¯»å–æ•°æ®æ–‡ä»¶çš„å‰å‡ è¡Œæ¥éªŒè¯æ ¼å¼
        sample_data = pd.read_excel(data_path, nrows=5)
        logger.info(f"æ•°æ®æ–‡ä»¶éªŒè¯æˆåŠŸ: {data_path}")
        logger.info(f"æ•°æ®å½¢çŠ¶: {sample_data.shape}")
        logger.info(f"åˆ—å: {list(sample_data.columns)}")
        return True
    except Exception as e:
        raise ValueError(f"æ•°æ®æ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}")


def run_complete_experiment_with_visualization(config_path='configs/config.yaml'):
    """è¿è¡Œå®Œæ•´å®éªŒå¹¶ç”Ÿæˆå¯è§†åŒ–ç»“æœ"""
    
    print("ğŸŒŠ æµ®å¼é£æœºå¹³å°è¿åŠ¨å“åº”é¢„æµ‹ - çœŸå®æ•°æ®å®éªŒ")
    print("=" * 60)
    
    try:
        # 1. éªŒè¯æ•°æ®æ–‡ä»¶
        data_path = Path(project_root) / 'data' / 'æµ®å¼é£æœºå¹³å°.xlsx'
        print(f"\n1. éªŒè¯æ•°æ®æ–‡ä»¶: {data_path}")
        validate_data_file(data_path)
        print("âœ“ æ•°æ®æ–‡ä»¶éªŒè¯æˆåŠŸ")
        
        # 2. åˆå§‹åŒ–å®éªŒ
        print(f"\n2. åˆå§‹åŒ–å®éªŒ...")
        experiment = FloatingWindPlatformExperiment(config_path)
        print("âœ“ å®éªŒåˆå§‹åŒ–å®Œæˆ")
        
        # 3. è¿è¡Œå®Œæ•´å®éªŒæµç¨‹
        print(f"\n3. è¿è¡Œå®Œæ•´å®éªŒæµç¨‹...")
        results = experiment.run_complete_experiment(optimize_hyperparameters=True)
        print("âœ“ å®éªŒè¿è¡Œå®Œæˆ")
        
        # 4. è·å–å®éªŒç»“æœç›®å½•
        results_dir = experiment.results_dir
        visualization_dir = experiment.visualization_dir
        
        print(f"\n4. å®éªŒç»“æœç›®å½•: {results_dir}")
        print(f"   å¯è§†åŒ–ç›®å½•: {visualization_dir}")
        
        # 5. è¯¦ç»†è¾“å‡ºç»“æœåˆ†æ
        print("\n" + "=" * 60)
        print("ğŸ“Š è¯¦ç»†å®éªŒç»“æœåˆ†æ")
        print("=" * 60)
        
        # åˆ›å»ºç»“æœDataFrame
        results_df = pd.DataFrame(results).T
        print("\nå„æ¨¡å‹æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”:")
        print(results_df.round(6))
        
        # 6. ç”Ÿæˆé¢å¤–çš„è¯¦ç»†åˆ†æå›¾è¡¨
        print(f"\n5. ç”Ÿæˆè¯¦ç»†åˆ†æå›¾è¡¨...")
        generate_detailed_analysis(experiment, results_dir)
        
        # 7. ä¿å­˜å®Œæ•´çš„ç»“æœæ‘˜è¦
        save_comprehensive_results(experiment, results, results_dir)
        
        print("\n" + "=" * 60)
        print("âœ… å®éªŒæˆåŠŸå®Œæˆï¼")
        print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {results_dir}")
        print("=" * 60)
        
        return results, results_dir
        
    except Exception as e:
        logger.error(f"å®éªŒè¿è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise


def generate_detailed_analysis(experiment, results_dir):
    """ç”Ÿæˆè¯¦ç»†çš„åˆ†æå›¾è¡¨"""
    
    visualization_dir = os.path.join(results_dir, 'detailed_analysis')
    os.makedirs(visualization_dir, exist_ok=True)
    
    # 1. æ¨¡å‹æ€§èƒ½é›·è¾¾å›¾
    create_performance_radar_chart(experiment.results, visualization_dir)
    
    # 2. è¯¯å·®åˆ†å¸ƒåˆ†æ
    create_error_distribution_analysis(experiment, visualization_dir)
    
    # 3. æ—¶é—´åºåˆ—é¢„æµ‹å¯¹æ¯”
    create_time_series_comparison(experiment, visualization_dir)
    
    # 4. ç­–ç•¥æƒé‡å˜åŒ–åˆ†æ
    if hasattr(experiment, 'strategy_c_results'):
        create_strategy_weights_analysis(experiment, visualization_dir)
    
    logger.info(f"è¯¦ç»†åˆ†æå›¾è¡¨å·²ä¿å­˜åˆ°: {visualization_dir}")


def create_performance_radar_chart(results, save_dir):
    """åˆ›å»ºæ€§èƒ½é›·è¾¾å›¾"""
    
    import math
    
    # å‡†å¤‡æ•°æ®
    metrics = ['RMSE', 'MAE', 'MAPE', 'R2', 'peak_rmse']
    models = list(results.keys())
    
    # å½’ä¸€åŒ–æ•°æ® (R2ä¸éœ€è¦å½’ä¸€åŒ–ï¼Œå…¶ä»–æŒ‡æ ‡éœ€è¦åå‘å½’ä¸€åŒ–)
    normalized_data = {}
    for model in models:
        normalized_data[model] = []
        for metric in metrics:
            value = results[model][metric]
            if metric == 'R2':
                # R2èŒƒå›´æ˜¯0-1ï¼Œç›´æ¥ä½¿ç”¨
                normalized_value = value
            elif metric in ['RMSE', 'MAE', 'MAPE', 'peak_rmse']:
                # è¿™äº›æŒ‡æ ‡è¶Šå°è¶Šå¥½ï¼Œéœ€è¦åå‘å½’ä¸€åŒ–
                all_values = [results[m][metric] for m in models]
                max_val = max(all_values)
                min_val = min(all_values)
                if max_val != min_val:
                    normalized_value = 1 - (value - min_val) / (max_val - min_val)
                else:
                    normalized_value = 0.5
            else:
                normalized_value = value
            
            normalized_data[model].append(normalized_value)
    
    # åˆ›å»ºé›·è¾¾å›¾
    angles = [n / float(len(metrics)) * 2 * math.pi for n in range(len(metrics))]
    angles += angles[:1]  # é—­åˆå›¾å½¢
    
    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
    
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
    
    for i, (model, data) in enumerate(normalized_data.items()):
        values = data + data[:1]  # é—­åˆå›¾å½¢
        ax.plot(angles, values, 'o-', linewidth=2, label=model, color=colors[i % len(colors)])
        ax.fill(angles, values, alpha=0.25, color=colors[i % len(colors)])
    
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(metrics)
    ax.set_ylim(0, 1)
    ax.set_title('æ¨¡å‹æ€§èƒ½é›·è¾¾å›¾å¯¹æ¯”', fontsize=16, pad=20)
    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
    ax.grid(True)
    
    plt.tight_layout()
    plt.savefig(os.path.join(save_dir, 'performance_radar_chart.png'), dpi=300, bbox_inches='tight')
    plt.close()


def create_error_distribution_analysis(experiment, save_dir):
    """åˆ›å»ºè¯¯å·®åˆ†å¸ƒåˆ†æ"""
    
    # è·å–çœŸå®å€¼
    y_true = experiment.y_test_original
    
    # è·å–å„ä¸ªæ¨¡å‹çš„é¢„æµ‹å€¼
    predictions = {
        'PatchTST': experiment.expert_predictions_original['patchtst'],
        'NHITS': experiment.expert_predictions_original['nhits'],
        'ç­–ç•¥A (é™æ€ä¼˜åŒ–æƒé‡)': experiment.strategy_a_results['predictions_original'],
        'ç­–ç•¥B (å¹¿ä¹‰çº¿æ€§èåˆ)': experiment.strategy_b_results['predictions_original'],
        'ç­–ç•¥C (åŠ¨æ€é—¨æ§ç½‘ç»œ)': experiment.strategy_c_results['predictions_original']
    }
    
    # è®¡ç®—è¯¯å·®
    errors = {}
    for name, pred in predictions.items():
        errors[name] = y_true - pred
    
    # åˆ›å»ºè¯¯å·®åˆ†å¸ƒå›¾
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.flatten()
    
    for i, (name, error) in enumerate(errors.items()):
        ax = axes[i]
        
        # ç»˜åˆ¶è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾
        ax.hist(error.flatten(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        ax.axvline(x=0, color='red', linestyle='--', linewidth=2)
        ax.set_title(f'{name} è¯¯å·®åˆ†å¸ƒ', fontsize=12)
        ax.set_xlabel('è¯¯å·®å€¼', fontsize=10)
        ax.set_ylabel('é¢‘æ¬¡', fontsize=10)
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        mean_error = np.mean(error.flatten())
        std_error = np.std(error.flatten())
        ax.text(0.05, 0.95, f'å‡å€¼: {mean_error:.4f}\næ ‡å‡†å·®: {std_error:.4f}', 
                transform=ax.transAxes, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    # ç§»é™¤æœ€åä¸€ä¸ªç©ºå­å›¾
    fig.delaxes(axes[-1])
    
    plt.tight_layout()
    plt.savefig(os.path.join(save_dir, 'error_distribution_analysis.png'), dpi=300, bbox_inches='tight')
    plt.close()


def create_time_series_comparison(experiment, save_dir):
    """åˆ›å»ºæ—¶é—´åºåˆ—é¢„æµ‹å¯¹æ¯”å›¾"""
    
    # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§çš„æ—¶é—´æ®µ
    n_examples = 3
    total_length = len(experiment.y_test_original)
    
    # éšæœºé€‰æ‹©èµ·å§‹ç‚¹
    np.random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§
    start_indices = np.random.choice(total_length - 100, n_examples, replace=False)
    
    for idx, start_idx in enumerate(start_indices):
        fig, ax = plt.subplots(figsize=(14, 8))
        
        # é€‰æ‹©100ä¸ªæ—¶é—´æ­¥çš„æ•°æ®
        end_idx = start_idx + 100
        time_range = range(100)
        
        # çœŸå®å€¼
        y_true_segment = experiment.y_test_original[start_idx:end_idx]
        
        # è·å–é¢„æµ‹å€¼
        predictions = {
            'çœŸå®å€¼': y_true_segment,
            'PatchTST': experiment.expert_predictions_original['patchtst'][start_idx:end_idx],
            'NHITS': experiment.expert_predictions_original['nhits'][start_idx:end_idx],
            'ç­–ç•¥A': experiment.strategy_a_results['predictions_original'][start_idx:end_idx],
            'ç­–ç•¥B': experiment.strategy_b_results['predictions_original'][start_idx:end_idx],
            'ç­–ç•¥C': experiment.strategy_c_results['predictions_original'][start_idx:end_idx]
        }
        
        # ç»˜åˆ¶æ—¶é—´åºåˆ—
        colors = ['black', '#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
        linestyles = ['-', '--', '--', '-.', '-.', ':']
        
        for i, (name, data) in enumerate(predictions.items()):
            if name == 'çœŸå®å€¼':
                ax.plot(time_range, data.flatten(), color=colors[i], linewidth=3, 
                       label=name, zorder=10)
            else:
                ax.plot(time_range, data.flatten(), color=colors[i], 
                       linestyle=linestyles[i], linewidth=2, label=name, alpha=0.8)
        
        ax.set_title(f'æ—¶é—´åºåˆ—é¢„æµ‹å¯¹æ¯” - ç¤ºä¾‹ {idx+1}', fontsize=14)
        ax.set_xlabel('æ—¶é—´æ­¥', fontsize=12)
        ax.set_ylabel('æ³¢æµªé«˜åº¦ (m)', fontsize=12)
        ax.legend(loc='best')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(save_dir, f'time_series_comparison_example_{idx+1}.png'),
                    dpi=300, bbox_inches='tight')
        plt.close()


def create_strategy_weights_analysis(experiment, save_dir):
    """åˆ›å»ºç­–ç•¥æƒé‡å˜åŒ–åˆ†æ"""
    
    if not hasattr(experiment, 'strategy_c_results'):
        return
    
    coefficients = experiment.strategy_c_results['coefficients']
    # coefficientså½¢çŠ¶: [n_samples, horizon, 3] - [w0, w1, w2]
    
    # é€‰æ‹©å‡ ä¸ªæ ·æœ¬åˆ†ææƒé‡å˜åŒ–
    n_samples = min(5, coefficients.shape[0])
    sample_indices = np.random.choice(coefficients.shape[0], n_samples, replace=False)
    
    fig, axes = plt.subplots(n_samples, 1, figsize=(14, 4*n_samples))
    if n_samples == 1:
        axes = [axes]
    
    for i, sample_idx in enumerate(sample_indices):
        ax = axes[i]
        
        time_steps = range(coefficients.shape[1])
        
        # ç»˜åˆ¶ä¸‰ä¸ªæƒé‡ç³»æ•°
        ax.plot(time_steps, coefficients[sample_idx, :, 0], 
                label='w0 (æˆªè·é¡¹)', color='red', linewidth=2)
        ax.plot(time_steps, coefficients[sample_idx, :, 1], 
                label='w1 (PatchTSTæƒé‡)', color='blue', linewidth=2)
        ax.plot(time_steps, coefficients[sample_idx, :, 2], 
                label='w2 (NHITSæƒé‡)', color='green', linewidth=2)
        
        # æ·»åŠ å‚è€ƒçº¿
        ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
        ax.axhline(y=1, color='gray', linestyle='--', alpha=0.5)
        
        ax.set_title(f'ç­–ç•¥CåŠ¨æ€æƒé‡å˜åŒ– - æ ·æœ¬ {sample_idx+1}', fontsize=12)
        ax.set_xlabel('æ—¶é—´æ­¥', fontsize=10)
        ax.set_ylabel('æƒé‡ç³»æ•°', fontsize=10)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ æƒé‡ç»Ÿè®¡ä¿¡æ¯
        w1_mean = np.mean(coefficients[sample_idx, :, 1])
        w2_mean = np.mean(coefficients[sample_idx, :, 2])
        ax.text(0.02, 0.98, f'å¹³å‡PatchTSTæƒé‡: {w1_mean:.3f}\nå¹³å‡NHITSæƒé‡: {w2_mean:.3f}', 
                transform=ax.transAxes, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.7))
    
    plt.tight_layout()
    plt.savefig(os.path.join(save_dir, 'strategy_c_weights_analysis.png'), 
                dpi=300, bbox_inches='tight')
    plt.close()


def save_comprehensive_results(experiment, results, results_dir):
    """ä¿å­˜ç»¼åˆç»“æœ"""
    
    # åˆ›å»ºç»“æœæ‘˜è¦æ–‡ä»¶
    summary_file = os.path.join(results_dir, 'comprehensive_results_summary.txt')
    
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write("æµ®å¼é£æœºå¹³å°è¿åŠ¨å“åº”é¢„æµ‹å®éªŒ - ç»¼åˆç»“æœæ‘˜è¦\n")
        f.write("=" * 60 + "\n")
        f.write(f"å®éªŒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ç»“æœç›®å½•: {results_dir}\n\n")
        
        f.write("ğŸ“Š æ¨¡å‹æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”:\n")
        f.write("-" * 40 + "\n")
        
        # å†™å…¥ç»“æœè¡¨æ ¼
        results_df = pd.DataFrame(results).T
        f.write(results_df.round(6).to_string())
        f.write("\n\n")
        
        # å†™å…¥æœ€ä½³æ¨¡å‹ä¿¡æ¯# ä¿®å¤å‰çš„ä»£ç ï¼ˆç¬¬130-132è¡Œï¼‰ï¼š
       # fig.update_layout(
         #   title=title,
          #  xaxis_title="æ—¶é—´æ­¥",
          #  yaxis_title="æ³¢é«˜",
          #  **PLOTLY_THEME['layout']
        #)

# ä¿®å¤åçš„ä»£ç ï¼š
        # åˆå¹¶å¸ƒå±€é…ç½®ï¼Œé¿å…titleå‚æ•°é‡å¤
        layout_config = PLOTLY_THEME['layout'].copy()
        layout_config.update({
            'title': title,
            'xaxis_title': "æ—¶é—´æ­¥",
            'yaxis_title': "æ³¢é«˜"
        })
        fig.update_layout(**layout_config)

        best_rmse_model = results_df['RMSE'].idxmin()
        best_r2_model = results_df['R2'].idxmax()
        best_mape_model = results_df['MAPE'].idxmin()
        
        f.write("ğŸ† æœ€ä½³æ¨¡å‹:\n")
        f.write(f"  - æœ€ä½RMSE: {best_rmse_model} (RMSE: {results[best_rmse_model]['RMSE']:.6f})\n")
        f.write(f"  - æœ€é«˜RÂ²: {best_r2_model} (RÂ²: {results[best_r2_model]['R2']:.6f})\n")
        f.write(f"  - æœ€ä½MAPE: {best_mape_model} (MAPE: {results[best_mape_model]['MAPE']:.6f}%)\n\n")
        
        # å†™å…¥å®éªŒé…ç½®ä¿¡æ¯
        f.write("âš™ï¸ å®éªŒé…ç½®:\n")
        f.write(f"  - é…ç½®æ–‡ä»¶: {experiment.config_path}\n")
        f.write(f"  - æ•°æ®æ–‡ä»¶: æµ®å¼é£æœºå¹³å°.xlsx\n")
        f.write(f"  - è®­ç»ƒæ ·æœ¬æ•°: {len(experiment.X_train)}\n")
        f.write(f"  - éªŒè¯æ ·æœ¬æ•°: {len(experiment.X_val)}\n")
        f.write(f"  - æµ‹è¯•æ ·æœ¬æ•°: {len(experiment.X_test)}\n")
        f.write(f"  - è¾“å…¥åºåˆ—é•¿åº¦: {experiment.X_train.shape[1]}\n")
        f.write(f"  - é¢„æµ‹ horizon: {experiment.y_train.shape[1]}\n\n")
        
        # å†™å…¥ç­–ç•¥ä¿¡æ¯
        if hasattr(experiment, 'strategy_a_results'):
            f.write("ğŸ“ˆ èåˆç­–ç•¥ä¿¡æ¯:\n")
            f.write(f"  - ç­–ç•¥Aæœ€ä¼˜æƒé‡: {experiment.strategy_a_results.get('weights', 'N/A')}\n")
            f.write(f"  - ç­–ç•¥Bæœ€ä¼˜ç³»æ•°: {experiment.strategy_b_results.get('coefficients', 'N/A')}\n")
            
            if hasattr(experiment, 'strategy_c_results'):
                coeffs = experiment.strategy_c_results['coefficients']
                f.write(f"  - ç­–ç•¥Cç³»æ•°èŒƒå›´: w0[{coeffs[:,:,0].min():.3f}, {coeffs[:,:,0].max():.3f}], ")
                f.write(f"w1[{coeffs[:,:,1].min():.3f}, {coeffs[:,:,1].max():.3f}], ")
                f.write(f"w2[{coeffs[:,:,2].min():.3f}, {coeffs[:,:,2].max():.3f}]\n")
    
    logger.info(f"ç»¼åˆç»“æœæ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")


def main():
    """ä¸»å‡½æ•°"""
    
    try:
        # è¿è¡Œå®Œæ•´å®éªŒ
        results, results_dir = run_complete_experiment_with_visualization()
        
        # æ‰“å°æœ€ç»ˆæˆåŠŸä¿¡æ¯
        print(f"\nğŸ‰ å®éªŒè¿è¡ŒæˆåŠŸï¼")
        print(f"ğŸ“Š ç»“æœæ‘˜è¦:")
        for model_name, metrics in results.items():
            print(f"  {model_name}:")
            print(f"    RMSE: {metrics['RMSE']:.6f}")
            print(f"    MAE:  {metrics['MAE']:.6f}")
            print(f"    MAPE: {metrics['MAPE']:.6f}%")
            print(f"    RÂ²:   {metrics['R2']:.6f}")
        
    except Exception as e:
        logger.error(f"å®éªŒè¿è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸš€ é¡¹ç›®å·²å‡†å¤‡å°±ç»ªï¼")
    else:
        print("\nâš ï¸  è¯·æ£€æŸ¥é”™è¯¯å¹¶é‡æ–°éƒ¨ç½²")