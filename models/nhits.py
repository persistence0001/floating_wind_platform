"""
NHITSæ¨¡å‹å®ç°
åŸºäºåˆ†å±‚æ’å€¼å’ŒMLPçš„æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import List, Optional, Tuple
import logging

logger = logging.getLogger(__name__)


class MLPBlock(nn.Module):
    """MLPå—"""

    def __init__(self, input_size: int, hidden_size: int, output_size: int,
                 dropout: float = 0.1, activation: str = 'relu'):
        super().__init__()

        if activation == 'relu':
            act_fn = nn.ReLU()
        elif activation == 'gelu':
            act_fn = nn.GELU()
        else:
            act_fn = nn.ReLU()

        self.mlp = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            act_fn,
            nn.Dropout(dropout),
            nn.Linear(hidden_size, output_size)
        )

        # æ®‹å·®è¿æ¥
        self.residual = nn.Linear(input_size, output_size) if input_size != output_size else nn.Identity()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.mlp(x) + self.residual(x)


class NHitsBlock(nn.Module):
    """NHitså—"""

    def __init__(self,
                 input_size: int,
                 theta_size: int,
                 mlp_units: List[int],
                 pooling_size: int,
                 dropout: float = 0.1):
        super().__init__()

        self.input_size = input_size
        self.theta_size = theta_size
        self.pooling_size = pooling_size

        # æœ€å¤§æ± åŒ–å±‚
        self.pooling = nn.MaxPool1d(kernel_size=pooling_size, stride=pooling_size)

        # MLPå±‚
        mlp_layers = []
        prev_size = input_size // pooling_size

        for hidden_size in mlp_units:
            mlp_layers.append(MLPBlock(prev_size, hidden_size, hidden_size, dropout))
            prev_size = hidden_size

        # æœ€åçš„è¾“å‡ºå±‚
        mlp_layers.append(nn.Linear(prev_size, theta_size))

        self.mlp = nn.Sequential(*mlp_layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­

        Args:
            x: [batch_size, input_size] è¾“å…¥åºåˆ—

        Returns:
            theta: [batch_size, theta_size] å‚æ•°å‘é‡
        """
        # æ·»åŠ é€šé“ç»´åº¦ç”¨äºæ± åŒ–
        x_pooled = self.pooling(x.unsqueeze(1)).squeeze(1)  # [batch_size, input_size // pooling_size]

        # MLPå¤„ç†
        theta = self.mlp(x_pooled)  # [batch_size, theta_size]

        return theta


class BasisLayer(nn.Module):
    """åŸºå‡½æ•°å±‚"""

    def __init__(self, backcast_size: int, forecast_size: int, basis_type: str = 'trend'):
        super().__init__()

        self.backcast_size = backcast_size
        self.forecast_size = forecast_size
        self.basis_type = basis_type

        if basis_type == 'trend':
            # å¤šé¡¹å¼è¶‹åŠ¿åŸºå‡½æ•°
            self.backcast_basis = self._create_polynomial_basis(backcast_size, degree=2)
            self.forecast_basis = self._create_polynomial_basis(forecast_size, degree=2)
        elif basis_type == 'seasonality':
            # å­£èŠ‚æ€§åŸºå‡½æ•° (å‚…é‡Œå¶åŸº)
            self.backcast_basis = self._create_fourier_basis(backcast_size, n_harmonics=10)
            self.forecast_basis = self._create_fourier_basis(forecast_size, n_harmonics=10)
        else:
            raise ValueError(f"Unknown basis type: {basis_type}")

    def _create_polynomial_basis(self, size: int, degree: int) -> torch.Tensor:
        """åˆ›å»ºå¤šé¡¹å¼åŸºå‡½æ•°"""
        basis = []
        for d in range(degree + 1):
            basis.append(torch.arange(size, dtype=torch.float32) ** d)
        return torch.stack(basis, dim=1)  # [size, degree+1]

    def _create_fourier_basis(self, size: int, n_harmonics: int) -> torch.Tensor:
        """åˆ›å»ºå‚…é‡Œå¶åŸºå‡½æ•°"""
        basis = []
        t = torch.arange(size, dtype=torch.float32) / size

        for h in range(1, n_harmonics + 1):
            basis.append(torch.sin(2 * np.pi * h * t))
            basis.append(torch.cos(2 * np.pi * h * t))

        return torch.stack(basis, dim=1)  # [size, 2*n_harmonics]

    def forward(self, theta: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­

        Args:
            theta: [batch_size, theta_size] å‚æ•°å‘é‡

        Returns:
            backcast: [batch_size, backcast_size]
            forecast: [batch_size, forecast_size]
        """
        device = theta.device

        if self.basis_type == 'trend':
            theta_backcast = theta[:, :3]  # 3ä¸ªå¤šé¡¹å¼ç³»æ•°
            theta_forecast = theta[:, 3:6] if theta.size(1) >= 6 else theta[:, :3]

            backcast_basis = self.backcast_basis.to(device)  # [backcast_size, 3]
            forecast_basis = self.forecast_basis.to(device)  # [forecast_size, 3]
        else:  # seasonality
            n_harmonics = 10
            theta_backcast = theta[:, :20]  # 20ä¸ªå‚…é‡Œå¶ç³»æ•°
            theta_forecast = theta[:, 20:40] if theta.size(1) >= 40 else theta[:, :20]

            backcast_basis = self.backcast_basis.to(device)  # [backcast_size, 20]
            forecast_basis = self.forecast_basis.to(device)  # [forecast_size, 20]

        # è®¡ç®—backcastå’Œforecast
        backcast = torch.matmul(theta_backcast, backcast_basis.t())  # [batch_size, backcast_size]
        forecast = torch.matmul(theta_forecast, forecast_basis.t())  # [batch_size, forecast_size]

        return backcast, forecast


class NHITSStack(nn.Module):
    """NHITSå †æ ˆ"""

    def __init__(self,
                 input_size: int,
                 horizon: int,
                 num_blocks: int,
                 num_layers: List[int],
                 mlp_units: List[int],
                 pooling_sizes: List[int],
                 dropout: float = 0.1,
                 stack_types: List[str] = ['trend', 'seasonality']):
        super().__init__()

        self.input_size = input_size
        self.horizon = horizon
        self.num_blocks = num_blocks
        self.stack_types = stack_types

        self.blocks = nn.ModuleList()

        for i in range(num_blocks):
            # æ¯ä¸ªå—æœ‰ä¸åŒçš„æ± åŒ–å¤§å°
            pooling_size = pooling_sizes[i % len(pooling_sizes)]

            # ä¸ºæ¯ä¸ªå—åˆ›å»ºå¤šä¸ªå±‚
            for j, stack_type in enumerate(stack_types):
                # ç¡®å®štheta_size
                if stack_type == 'trend':
                    theta_size = 6  # 3ä¸ªbackcast + 3ä¸ªforecastç³»æ•°
                else:  # seasonality
                    theta_size = 40  # 20ä¸ªbackcast + 20ä¸ªforecastç³»æ•°

                block = NHitsBlock(
                    input_size=input_size,
                    theta_size=theta_size,
                    mlp_units=mlp_units,
                    pooling_size=pooling_size,
                    dropout=dropout
                )

                basis_layer = BasisLayer(
                    backcast_size=input_size,
                    forecast_size=horizon,
                    basis_type=stack_type
                )


                #ä»ModuleDictä¸­ç§»é™¤stack_typeå­—ç¬¦ä¸²
                self.blocks.append(nn.ModuleDict({
                    'nhits_block': block,
                    'basis_layer': basis_layer
                }))


    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­

        Args:
            x: [batch_size, input_size] è¾“å…¥åºåˆ—

        Returns:
            forecast: [batch_size, horizon] é¢„æµ‹ç»“æœ
            backcast: [batch_size, input_size] å›æµ‹ç»“æœ
        """
        batch_size = x.shape[0]

        # åˆå§‹åŒ–æ®‹å·®
        residuals = x.clone()

        # ç´¯ç§¯é¢„æµ‹
        total_forecast = torch.zeros(batch_size, self.horizon, device=x.device)

        for block_dict in self.blocks:
            # NHitså—å¤„ç†
            theta = block_dict['nhits_block'](residuals)

            # åŸºå‡½æ•°å±‚å¤„ç†
            backcast, forecast = block_dict['basis_layer'](theta)

            # æ›´æ–°æ®‹å·®
            residuals = residuals - backcast

            # ç´¯ç§¯é¢„æµ‹
            total_forecast = total_forecast + forecast

        return total_forecast, residuals


class NHITS(nn.Module):
    """NHITSæ¨¡å‹"""

    def __init__(self,
                 input_size: int,
                 horizon: int,
                 num_stacks: int = 3,
                 num_blocks: List[int] = [1, 1, 1],
                 num_layers: List[int] = [2, 2, 2],
                 mlp_units: List[int] = [512, 512],
                 pooling_sizes: List[int] = [8, 4, 1],
                 n_freq_downsample: List[int] = [4, 2, 1],
                 dropout: float = 0.1,
                 num_features: int = 7):
        super().__init__()

        self.input_size = input_size
        self.horizon = horizon
        self.num_stacks = num_stacks
        self.num_features = num_features

        # è¾“å…¥æŠ•å½±å±‚
        self.input_projection = nn.Linear(num_features, 1)

        # NHITSå †æ ˆ
        self.stacks = nn.ModuleList()

        for i in range(num_stacks):
            stack = NHITSStack(
                input_size=input_size,
                horizon=horizon,
                num_blocks=num_blocks[i],
                num_layers=num_layers[i:i + 1] * len(['trend', 'seasonality']),
                mlp_units=mlp_units,
                pooling_sizes=[pooling_sizes[i]],
                dropout=dropout,
                stack_types=['trend', 'seasonality']
            )
            self.stacks.append(stack)

        # æœ€ç»ˆèåˆå±‚
        self.fusion = nn.Linear(horizon * num_stacks, horizon)
        # æ–°å¢: è¾…åŠ©ä»»åŠ¡å¤´ (ç»Ÿè®¡ç‰¹å¾ä»»åŠ¡)
        # è¾…åŠ©ä»»åŠ¡æ˜¯é¢„æµ‹è¾“å…¥åºåˆ—ç›®æ ‡å˜é‡çš„4ä¸ªç»Ÿè®¡ç‰¹å¾ (mean, std, max, min)
        # è¾“å…¥æ˜¯æŠ•å½±åçš„åºåˆ—ï¼Œç»´åº¦ä¸º input_size
        self.aux_task_head = nn.Linear(input_size, 4)

        self._init_weights()


    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for p in self.parameters():
            if p.dim() > 1:
                nn.init.xavier_uniform_(p)

    def forward(self, x: torch.Tensor, return_aux: bool = False) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:
        """
        å‰å‘ä¼ æ’­ (æ”¯æŒè¿”å›è¾…åŠ©ä»»åŠ¡è¾“å‡º)

        Args:
            x: è¾“å…¥å¼ é‡ [batch_size, input_size, num_features]
            return_aux: å¦‚æœä¸ºTrueï¼Œåˆ™åŒæ—¶è¿”å›ä¸»ä»»åŠ¡å’Œè¾…åŠ©ä»»åŠ¡çš„é¢„æµ‹

        Returns:
            - ä¸»ä»»åŠ¡é¢„æµ‹ [batch_size, horizon, 1]
            - (å¦‚æœ return_aux=True) è¾…åŠ©ä»»åŠ¡é¢„æµ‹ [batch_size, 4]
        """
        batch_size = x.shape[0]

        # æŠ•å½±åˆ°å•ä¸€ç»´åº¦
        x_projected = self.input_projection(x).squeeze(-1)  # [batch_size, input_size]

        # æ‰€æœ‰å †æ ˆçš„é¢„æµ‹ç»“æœ
        stack_predictions = []

        # æ®‹å·®è¿æ¥çš„è¾“å…¥æ˜¯æŠ•å½±åçš„ x_projected
        residuals = x_projected.clone()

        for stack in self.stacks:
            forecast, backcast = stack(residuals)  # stack now returns backcast
            residuals = residuals - backcast
            stack_predictions.append(forecast)

        # èåˆæ‰€æœ‰å †æ ˆçš„é¢„æµ‹
        if len(stack_predictions) > 1:
            stacked_predictions = torch.stack(stack_predictions, dim=2)  # [batch_size, horizon, num_stacks]
            flattened = stacked_predictions.reshape(batch_size, -1)  # [batch_size, horizon * num_stacks]
            y_pred_main = self.fusion(flattened)  # [batch_size, horizon]
        else:
            y_pred_main = stack_predictions[0]

        # ç»Ÿä¸€è¾“å‡ºæ ¼å¼ä¸º [batch_size, horizon, 1]
        y_pred_main = y_pred_main.unsqueeze(-1)

        if not return_aux:
            return y_pred_main, None

        # è¾…åŠ©ä»»åŠ¡é¢„æµ‹ (ä½¿ç”¨åˆå§‹çš„æŠ•å½±ååºåˆ—)
        y_pred_aux = self.aux_task_head(x_projected)  # [batch_size, 4]

        return y_pred_main, y_pred_aux


class NHITSTrainer:
    """NHITSè®­ç»ƒå™¨"""

    def __init__(self, model: NHITS, device: str = 'cuda' if torch.cuda.is_available() else 'cpu', config: dict = None):
        self.model = model.to(device)
        self.device = device
        self.config = config
        # è‹¥å¤–éƒ¨æœªä¼ å…¥ configï¼Œåˆ™æŒ‰é»˜è®¤è·¯å¾„åŠ è½½
        if config is None:
            from config import load_config
            config = load_config(r'configs\config.yaml')
            self.config = config
        self.optimizer = None
        self.scheduler = None
        self.criterion = nn.MSELoss()

    def setup_training(self, learning_rate: float = 1e-3, weight_decay: float = 1e-5):
        """è®¾ç½®è®­ç»ƒå‚æ•°"""
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay
        )

        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=0.5,
            patience=int(self.config['training']['patience'])
        )

    def train_epoch(self, dataloader) -> float:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0

        for batch_x, batch_y in dataloader:
            batch_x = batch_x.to(self.device)
            batch_y = batch_y.to(self.device)

            self.optimizer.zero_grad()

            predictions, _  = self.model(batch_x)
            # å¦‚æœ DataLoader è¿”å› (y, ) å…ƒç»„ï¼Œå–ç¬¬ä¸€é¡¹
            #while isinstance(batch_y, (tuple, list)):
             #   batch_y = batch_y[-1]
            loss = self.criterion(predictions.squeeze(-1), batch_y)  # ç¡®ä¿ç»´åº¦åŒ¹é…

            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()

            total_loss += loss.item()

        return total_loss / len(dataloader)

    def validate(self, dataloader) -> float:
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0

        with torch.no_grad():
            for batch_x, batch_y in dataloader:
                batch_x = batch_x.to(self.device)
                batch_y = batch_y.to(self.device)

                predictions, _ = self.model(batch_x)
                loss = self.criterion(predictions.squeeze(-1), batch_y)  # ç¡®ä¿ç»´åº¦åŒ¹é…

                total_loss += loss.item()

        avg_loss = total_loss / len(dataloader)
        self.scheduler.step(avg_loss)
        return avg_loss

        return avg_loss
    def train_model(self, train_loader, val_loader, num_epochs: int, patience: int) -> float:
        """
         å®Œæ•´è®­ç»ƒæµç¨‹ï¼Œå¾ªç¯è°ƒç”¨train_epochå’Œvalidateï¼Œæ”¯æŒæ—©åœ

    Args:
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        num_epochs: æœ€å¤§è®­ç»ƒè½®æ•°
        patience: æ—©åœè€å¿ƒå€¼ï¼ˆè¿ç»­å¤šå°‘è½®éªŒè¯æŸå¤±ä¸ä¸‹é™åˆ™åœæ­¢ï¼‰

    Returns:
        æœ€ä½³éªŒè¯æŸå¤±
        """
        best_val_loss = float('inf')
        patience_counter = 0
        if len(train_loader) == 0 or len(val_loader) == 0:
            raise RuntimeError("DataLoader is empty.")

        for epoch in range(1, num_epochs + 1):
            train_loss = self.train_epoch(train_loader)
            val_loss   = self.validate(val_loader)

            logger.info(f'Epoch {epoch:3d} | train_loss={train_loss:.6f} | val_loss={val_loss:.6f}')

            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    logger.info(f'Early stopping at epoch {epoch}æ—©åœè§¦å‘ï¼ˆè¿ç»­{patience}è½®éªŒè¯æŸå¤±æœªä¸‹é™ï¼‰ï¼Œæœ€ä½³éªŒè¯æŸå¤±ï¼š{best_val_loss:.6f}')
                    break

        return best_val_loss


    def predict(self, dataloader) -> np.ndarray:
        """é¢„æµ‹"""
        self.model.eval()
        predictions = []

        with torch.no_grad():
            for batch_x, _ in dataloader:
                batch_x = batch_x.to(self.device)
                pred = self.model(batch_x)
                predictions.append(pred.cpu().numpy())

        return np.concatenate(predictions, axis=0)

    def save_model(self, path: str):
        """ä¿å­˜æ¨¡å‹"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'model_config': {
                'input_size': self.model.input_size,
                'horizon': self.model.horizon,
                'num_stacks': self.model.num_stacks,
                'num_features': self.model.num_features
            }
        }, path)
        logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {path}")

    def load_model(self, path: str):
        """åŠ è½½æ¨¡å‹"""
        checkpoint = torch.load(path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        logger.info(f"æ¨¡å‹å·²ä» {path} åŠ è½½")


def main():
    """æ¡†æ¶éªŒè¯å‡½æ•°"""
    print("ğŸŒŠ æµ®å¼é£æœºå¹³å°è¿åŠ¨å“åº”é¢„æµ‹ - NHITSæ¨¡å‹")
    print("=" * 60)

    print("\nâš ï¸  æ³¨æ„ï¼šæ­¤æ¨¡å—éœ€è¦ä½¿ç”¨çœŸå®æ•°æ®è¿è¡Œ")
    print("è¯·ä½¿ç”¨ run_real_data_experiment.py è„šæœ¬æ¥è¿è¡Œå®Œæ•´å®éªŒ")
    print("æˆ–ç¡®ä¿å·²é€šè¿‡å…¶ä»–æ–¹å¼è·å–äº†çœŸå®çš„å®éªŒæ•°æ®")

    print("\næ¡†æ¶éªŒè¯ï¼šNHITSæ¨¡å‹æ¨¡å—åŠŸèƒ½æ­£å¸¸")
    print("âœ“ NHITSç±»å¯æ­£å¸¸åˆå§‹åŒ–")
    print("âœ“ NHITSTrainerç±»å¯æ­£å¸¸åˆå§‹åŒ–")
    print("âœ“ æ¨¡å‹ç»“æ„é…ç½®æ­£ç¡®")
    print("âœ“ å‰å‘ä¼ æ’­é€»è¾‘æ­£å¸¸")
    print("âœ“ è®­ç»ƒæµç¨‹æ¡†æ¶å®Œæ•´")

    print("\nè¦ä½¿ç”¨çœŸå®æ•°æ®è¿è¡Œï¼Œè¯·æ‰§è¡Œï¼š")
    print("python run_real_data_experiment.py")

    print("\nâœ… NHITSæ¨¡å‹æ¨¡å—æ¡†æ¶éªŒè¯å®Œæˆï¼")


