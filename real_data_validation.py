"""
çœŸå®æ•°æ®éªŒè¯è„šæœ¬
åŸºäºæµ®å¼é£æœºå¹³å°.xlsxæ•°æ®è¿›è¡Œå¿«é€ŸéªŒè¯
"""

import numpy as np
import torch
import sys
import logging
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from src.data_preprocessing.data_loader import DataLoader
from models.patchtst import PatchTST
from models.nhits import NHITS
from src.strategies.mpa_optimizer import MPAOptimizer, StackingOptimizer

from src.evaluation.metrics import EvaluationMetrics
from src.visualization.plots import VisualizationEngine

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def validate_data_loading():
    """éªŒè¯æ•°æ®åŠ è½½"""
    print("=" * 60)
    print("æ­¥éª¤1: éªŒè¯çœŸå®æ•°æ®åŠ è½½")
    print("=" * 60)
    
    try:
        # ä½¿ç”¨é…ç½®æ–‡ä»¶åŠ è½½çœŸå®æ•°æ®
        config_path = project_root / "configs" / "config.yaml"
        data_loader = DataLoader(str(config_path))
        
        # åŠ è½½æ•°æ®
        data = data_loader.load_data()
        print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸ: {data.shape}")
        print(f"âœ“ æ•°æ®åˆ—: {list(data.columns)}")
        
        # æ•°æ®é¢„å¤„ç†
        target_scaled, covariate_scaled, time_stamps = data_loader.preprocess_data()
        print(f"âœ“ ç›®æ ‡å˜é‡æ ‡å‡†åŒ–: {target_scaled.shape}")
        print(f"âœ“ åå˜é‡æ ‡å‡†åŒ–: {covariate_scaled.shape}")
        
        # åˆ›å»ºåºåˆ—
        X, y = data_loader.create_sequences(target_scaled, covariate_scaled)
        print(f"âœ“ åºåˆ—åˆ›å»ºå®Œæˆ: X{X.shape}, y{y.shape}")
        
        # æ•°æ®åˆ’åˆ†
        X_train, X_val, X_test, y_train, y_val, y_test = data_loader.split_data(X, y)
        print(f"âœ“ è®­ç»ƒé›†: X{X_train.shape}, y{y_train.shape}")
        print(f"âœ“ éªŒè¯é›†: X{X_val.shape}, y{y_val.shape}")
        print(f"âœ“ æµ‹è¯•é›†: X{X_test.shape}, y{y_test.shape}")
        
        return X_train, X_val, X_test, y_train, y_val, y_test
        
    except Exception as e:
        print(f"âœ— æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        raise


def validate_models_quick(X_train, y_train, X_val, y_val):
    """å¿«é€ŸéªŒè¯æ¨¡å‹ï¼ˆä½¿ç”¨å°‘é‡epochï¼‰"""
    """å¿«é€ŸéªŒè¯æ¨¡å‹ï¼ˆä½¿ç”¨å°‘é‡epochï¼‰"""
    # æ·»åŠ è¾“å…¥éªŒè¯æ£€æŸ¥
    if X_train is None or y_train is None or X_val is None or y_val is None:
        raise ValueError("validate_models_quick: è¾“å…¥æ•°æ®ä¸èƒ½ä¸ºNoneã€‚è¯·å…ˆåŠ è½½æ•°æ®ã€‚")

    if len(X_train) == 0 or len(y_train) == 0 or len(X_val) == 0 or len(y_val) == 0:
        raise ValueError("validate_models_quick: è¾“å…¥æ•°æ®ä¸èƒ½ä¸ºç©ºæ•°ç»„ã€‚")

    if X_train.shape[0] != y_train.shape[0] or X_val.shape[0] != y_val.shape[0]:
        raise ValueError("validate_models_quick: è¾“å…¥æ•°æ®çš„æ ·æœ¬æ•°é‡ä¸åŒ¹é…ã€‚")

    print("\n" + "=" * 60)
    print("æ­¥éª¤2: å¿«é€Ÿæ¨¡å‹éªŒè¯ï¼ˆ5ä¸ªepochï¼‰")
    print("=" * 60)

    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ¨¡å‹å‚æ•°
    batch_size = 32
    input_size = X_train.shape[1]
    horizon = y_train.shape[1]
    num_features = X_train.shape[2]
    
    print(f"æ¨¡å‹å‚æ•°: input_size={input_size}, horizon={horizon}, num_features={num_features}")
    
    # è®­ç»ƒPatchTSTï¼ˆå¿«é€Ÿ
    #
    # æ¨¡å¼ï¼‰
    print("\nè®­ç»ƒPatchTSTæ¨¡å‹...")
    patchtst = PatchTST(input_size=input_size, horizon=horizon, num_features=num_features)
    patchtst_train_loss = train_model_quick(patchtst, X_train, y_train, device, epochs=5)
    
    # è®­ç»ƒNHITSï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
    print("\nè®­ç»ƒNHITSæ¨¡å‹...")
    nhits = NHITS(input_size=input_size, horizon=horizon, num_features=num_features)
    nhits_train_loss = train_model_quick(nhits, X_train, y_train, device, epochs=5)
    
    # éªŒè¯é›†é¢„æµ‹
    print("\néªŒè¯é›†é¢„æµ‹...")
    with torch.no_grad():
        X_val_tensor = torch.FloatTensor(X_val).to(device)
        patchtst_pred = patchtst(X_val_tensor).cpu().numpy()
        nhits_pred = nhits(X_val_tensor).cpu().numpy()
    
    # è®¡ç®—éªŒè¯æŒ‡æ ‡
    patchtst_metrics = EvaluationMetrics.calculate_all_metrics(y_val, patchtst_pred)
    nhits_metrics = EvaluationMetrics.calculate_all_metrics(y_val, nhits_pred)
    
    print(f"\nPatchTSTéªŒè¯æŒ‡æ ‡:")
    print(f"  RMSE: {patchtst_metrics['RMSE']:.6f}")
    print(f"  MAE: {patchtst_metrics['MAE']:.6f}")
    print(f"  MAPE: {patchtst_metrics['MAPE']:.6f}%")
    
    print(f"\nNHITSéªŒè¯æŒ‡æ ‡:")
    print(f"  RMSE: {nhits_metrics['RMSE']:.6f}")
    print(f"  MAE: {nhits_metrics['MAE']:.6f}")
    print(f"  MAPE: {nhits_metrics['MAPE']:.6f}%")
    
    return patchtst, nhits, patchtst_pred, nhits_pred, patchtst_metrics, nhits_metrics


def train_model_quick(model, X_train, y_train, device, epochs=5):
    """å¿«é€Ÿè®­ç»ƒæ¨¡å‹"""
    # æ·»åŠ è¾“å…¥éªŒè¯æ£€æŸ¥
    if model is None:
        raise ValueError("train_model_quick: æ¨¡å‹ä¸èƒ½ä¸ºNoneã€‚")

    if X_train is None or y_train is None:
        raise ValueError("train_model_quick: è®­ç»ƒæ•°æ®ä¸èƒ½ä¸ºNoneã€‚")

    if len(X_train) == 0 or len(y_train) == 0:
        raise ValueError("train_model_quick: è®­ç»ƒæ•°æ®ä¸èƒ½ä¸ºç©ºæ•°ç»„ã€‚")

    if X_train.shape[0] != y_train.shape[0]:
        raise ValueError("train_model_quick: X_trainå’Œy_trainçš„æ ·æœ¬æ•°é‡ä¸åŒ¹é…ã€‚")

    model = model.to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = torch.nn.MSELoss()
    
    # ç®€å•çš„æ•°æ®åŠ è½½å™¨
    batch_size = 32
    n_batches = len(X_train) // batch_size
    
    train_losses = []
    
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        
        for i in range(n_batches):
            start_idx = i * batch_size
            end_idx = (i + 1) * batch_size
            
            X_batch = torch.FloatTensor(X_train[start_idx:end_idx]).to(device)
            y_batch = torch.FloatTensor(y_train[start_idx:end_idx]).to(device)
            
            optimizer.zero_grad()
            pred = model(X_batch)
            loss = criterion(pred, y_batch)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
        
        avg_loss = total_loss / n_batches
        train_losses.append(avg_loss)
        print(f"  Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}")
    
    return train_losses


def validate_fusion_strategies(y_true, patchtst_pred, nhits_pred):
    """éªŒè¯èåˆç­–ç•¥ï¼ˆä½¿ç”¨çœŸå®æ•°æ®ï¼‰"""
    # æ·»åŠ è¾“å…¥éªŒè¯æ£€æŸ¥
    if y_true is None or patchtst_pred is None or nhits_pred is None:
        raise ValueError("validate_fusion_strategies: è¾“å…¥é¢„æµ‹æ•°æ®ä¸èƒ½ä¸ºNoneã€‚")

    if len(y_true) == 0 or len(patchtst_pred) == 0 or len(nhits_pred) == 0:
        raise ValueError("validate_fusion_strategies: è¾“å…¥é¢„æµ‹æ•°æ®ä¸èƒ½ä¸ºç©ºæ•°ç»„ã€‚")

    if y_true.shape != patchtst_pred.shape or y_true.shape != nhits_pred.shape:
        raise ValueError("validate_fusion_strategies: è¾“å…¥é¢„æµ‹æ•°æ®çš„å½¢çŠ¶ä¸åŒ¹é…ã€‚")

    print("\n" + "=" * 60)
    print("æ­¥éª¤3: éªŒè¯èåˆç­–ç•¥ï¼ˆMPA 20æ¬¡è¿­ä»£ï¼‰")
    print("=" * 60)
    
    # å‡†å¤‡ä¸“å®¶é¢„æµ‹æ•°æ®
    expert_predictions = np.stack([patchtst_pred, nhits_pred], axis=2)
    print(f"ä¸“å®¶é¢„æµ‹æ•°æ®å½¢çŠ¶: {expert_predictions.shape}")
    print(f"çœŸå®å€¼å½¢çŠ¶: {y_true.shape}")
    
    # MPAé…ç½®ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
    mpa_config = {
        'population_size': 20,
        'max_iterations': 20,  # å¿«é€ŸéªŒè¯
        'fads_probability': 0.2,
        'convergence_threshold': 1e-4
    }
    
    # ç­–ç•¥Aï¼šé™æ€æƒé‡ä¼˜åŒ–
    print("\nç­–ç•¥A: é™æ€æƒé‡ä¼˜åŒ–...")
    static_optimizer = MPAOptimizer.StaticWeightOptimizer(mpa_config)
    weights_a, score_a = static_optimizer.optimize_weights(expert_predictions, y_true)
    
    # è®¡ç®—ç­–ç•¥Aé¢„æµ‹
    strategy_a_pred = np.zeros_like(y_true)
    for i, weight in enumerate(weights_a):
        strategy_a_pred += weight * expert_predictions[:, :, i]
    
    print(f"æœ€ä¼˜æƒé‡: {weights_a}")
    print(f"RMSE: {score_a:.6f}")
    
    # ç­–ç•¥Bï¼šå¹¿ä¹‰çº¿æ€§èåˆ
    print("\nç­–ç•¥B: å¹¿ä¹‰çº¿æ€§èåˆ...")
    stacking_optimizer = StackingOptimizer(mpa_config)
    coefficients_b, score_b = stacking_optimizer.optimize_coefficients(expert_predictions, y_true)
    
    # è®¡ç®—ç­–ç•¥Bé¢„æµ‹
    w0 = coefficients_b[0]
    weights_b = coefficients_b[1:]
    strategy_b_pred = np.full_like(y_true, w0)
    for i, weight in enumerate(weights_b):
        strategy_b_pred += weight * expert_predictions[:, :, i]
    
    print(f"æœ€ä¼˜ç³»æ•°: {coefficients_b}")
    print(f"RMSE: {score_b:.6f}")
    
    # è®¡ç®—å„ç­–ç•¥æŒ‡æ ‡
    strategy_a_metrics = EvaluationMetrics.calculate_all_metrics(y_true, strategy_a_pred)
    strategy_b_metrics = EvaluationMetrics.calculate_all_metrics(y_true, strategy_b_pred)
    
    print(f"\nç­–ç•¥AæŒ‡æ ‡: RMSE={strategy_a_metrics['RMSE']:.6f}, MAE={strategy_a_metrics['MAE']:.6f}")
    print(f"ç­–ç•¥BæŒ‡æ ‡: RMSE={strategy_b_metrics['RMSE']:.6f}, MAE={strategy_b_metrics['MAE']:.6f}")
    
    return {
        'strategy_a': {'pred': strategy_a_pred, 'metrics': strategy_a_metrics, 'weights': weights_a},
        'strategy_b': {'pred': strategy_b_pred, 'metrics': strategy_b_metrics, 'coefficients': coefficients_b},
        'experts': {'patchtst': patchtst_pred, 'nhits': nhits_pred}
    }


def generate_validation_plots(y_true, results):
    """ç”ŸæˆéªŒè¯å›¾è¡¨"""
    print("\n" + "=" * 60)
    print("æ­¥éª¤4: ç”ŸæˆéªŒè¯å›¾è¡¨")
    print("=" * 60)
    
    # åˆ›å»ºå¯è§†åŒ–å¼•æ“
    viz_engine = VisualizationEngine("real_validation_results")
    
    # å‡†å¤‡é¢„æµ‹æ•°æ®
    predictions = {
        'PatchTST': results['experts']['patchtst'],
        'NHITS': results['experts']['nhits'],
        'Strategy_A_Static': results['strategy_a']['pred'],
        'Strategy_B_Stacking': results['strategy_b']['pred']
    }
    
    # æ€§èƒ½å¯¹æ¯”å›¾
    print("ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾...")
    metrics = {
        'PatchTST': results['experts']['patchtst_metrics'],
        'NHITS': results['experts']['nhits_metrics'],
        'Strategy_A_Static': results['strategy_a']['metrics'],
        'Strategy_B_Stacking': results['strategy_b']['metrics']
    }
    
    perf_path = viz_engine.plot_performance_comparison(metrics)
    print(f"âœ“ æ€§èƒ½å¯¹æ¯”å›¾: {perf_path}")
    
    # æ—¶é—´åºåˆ—å¯¹æ¯”å›¾ï¼ˆå‰3ä¸ªæ ·æœ¬ï¼‰
    print("ç”Ÿæˆæ—¶é—´åºåˆ—å¯¹æ¯”å›¾...")
    for i in range(min(3, len(y_true))):
        ts_path = viz_engine.plot_time_series_comparison(y_true, predictions, sample_idx=i)
        print(f"âœ“ æ ·æœ¬{i}æ—¶é—´åºåˆ—å›¾: {ts_path}")
    
    # å³°å€¼è¯¯å·®åˆ†æ
    print("ç”Ÿæˆå³°å€¼è¯¯å·®åˆ†æå›¾...")
    peak_path = viz_engine.plot_peak_error_analysis(y_true, predictions)
    print(f"âœ“ å³°å€¼è¯¯å·®åˆ†æ: {peak_path}")
    
    # æ®‹å·®åˆ†æ
    print("ç”Ÿæˆæ®‹å·®åˆ†æå›¾...")
    residual_path = viz_engine.plot_residual_analysis(y_true, predictions)
    print(f"âœ“ æ®‹å·®åˆ†æ: {residual_path}")
    
    return viz_engine


def main():
    """ä¸»å‡½æ•°ï¼šçœŸå®æ•°æ®å¿«é€ŸéªŒè¯"""
    print("ğŸŒŠ æµ®å¼é£æœºå¹³å° - çœŸå®æ•°æ®å¿«é€ŸéªŒè¯")
    print("=" * 60)
    print("ä½¿ç”¨çœŸå®æ•°æ®éªŒè¯ç³»ç»ŸåŠŸèƒ½ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰")
    print("é¢„æœŸè¿è¡Œæ—¶é—´: 15-20åˆ†é’Ÿ")
    print("=" * 60)
    
    try:
        # æ­¥éª¤1: æ•°æ®åŠ è½½éªŒè¯
        X_train, X_val, X_test, y_train, y_val, y_test = validate_data_loading()
        
        # æ­¥éª¤2: æ¨¡å‹å¿«é€ŸéªŒè¯
        patchtst, nhits, patchtst_pred, nhits_pred, patchtst_metrics, nhits_metrics = \
            validate_models_quick(X_train, y_train, X_val, y_val)
        
        # å­˜å‚¨ä¸“å®¶æŒ‡æ ‡ä¾›åç»­ä½¿ç”¨
        experts_data = {
            'patchtst': {'pred': patchtst_pred, 'metrics': patchtst_metrics},
            'nhits': {'pred': nhits_pred, 'metrics': nhits_metrics}
        }
        
        # æ­¥éª¤3: èåˆç­–ç•¥éªŒè¯
        results = validate_fusion_strategies(y_val, patchtst_pred, nhits_pred)
        results['experts'] = experts_data
        
        # æ­¥éª¤4: ç”Ÿæˆå›¾è¡¨
        viz_engine = generate_validation_plots(y_val, results)
        
        # æ€»ç»“
        print("\n" + "=" * 60)
        print("âœ… çœŸå®æ•°æ®éªŒè¯å®Œæˆï¼")
        print("=" * 60)
        print("éªŒè¯ç»“æœæ‘˜è¦:")
        print(f"æ•°æ®åŠ è½½: âœ“ æˆåŠŸ ({X_train.shape[0]}è®­ç»ƒæ ·æœ¬)")
        print(f"PatchTST: RMSE={patchtst_metrics['RMSE']:.6f}")
        print(f"NHITS: RMSE={nhits_metrics['RMSE']:.6f}")
        print(f"ç­–ç•¥A: RMSE={results['strategy_a']['metrics']['RMSE']:.6f}, æƒé‡={results['strategy_a']['weights']}")
        print(f"ç­–ç•¥B: RMSE={results['strategy_b']['metrics']['RMSE']:.6f}")
        print("\nå›¾è¡¨å·²ä¿å­˜åˆ° results/real_validation_results/ ç›®å½•")
        print("âœ… ç³»ç»ŸéªŒè¯é€šè¿‡ï¼Œå¯ä»¥è¿›è¡Œå®Œæ•´å®éªŒï¼")
        
    except Exception as e:
        print(f"\nâŒ éªŒè¯å¤±è´¥: {str(e)}")
        raise


if __name__ == "__main__":
    main()