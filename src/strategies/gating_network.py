"""
åŠ¨æ€é—¨æ§ç½‘ç»œï¼ˆä¼˜åŒ–ç‰ˆï¼‰
æ”¯æŒå…¨ç‰¹å¾è¾“å…¥ + åå˜é‡-æƒé‡ç›¸å…³æ€§åˆ†æ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Optional, Tuple
import logging

logger = logging.getLogger(__name__)


class LSTMEncoder(nn.Module):
    """LSTMç¼–ç å™¨"""

    def __init__(self,
                 input_size: int,
                 hidden_size: int,
                 num_layers: int = 2,
                 dropout: float = 0.1,
                 bidirectional: bool = False):
        super().__init__()

        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.bidirectional = bidirectional

        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout if num_layers > 1 else 0,
            bidirectional=bidirectional,
            batch_first=True
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        Args:
            x: [batch_size, seq_len, input_size] è¾“å…¥åºåˆ—ï¼ˆå…¨ç‰¹å¾ï¼‰
        Returns:
            hidden_state: [batch_size, hidden_size * num_directions] æœ€åéšè—çŠ¶æ€
        """
        lstm_output, (hidden, cell) = self.lstm(x)

        if self.bidirectional:
            hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)  # [batch_size, hidden_size * 2]
        else:
            hidden = hidden[-1]  # [batch_size, hidden_size]

        return hidden


class GatingNetwork(nn.Module):
    """åŠ¨æ€é—¨æ§ç½‘ç»œï¼ˆæ”¯æŒå…¨ç‰¹å¾è¾“å…¥ï¼‰"""

    def __init__(self,
                 input_size: int,  # è¾“å…¥ç‰¹å¾æ€»æ•°
                 hidden_size: int = 64,
                 num_layers: int = 2,
                 horizon: int = 24,
                 n_experts: int = 2,
                 dropout: float = 0.1):
        super().__init__()

        self.input_size = input_size  # ç‰¹å¾æ€»æ•°
        self.hidden_size = hidden_size
        self.horizon = horizon
        self.n_experts = n_experts

        # LSTMç¼–ç å™¨ï¼ˆè¾“å…¥ä¸ºå…¨ç‰¹å¾ï¼‰
        self.encoder = LSTMEncoder(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout
        )

        # åŠ¨æ€ç³»æ•°ç”Ÿæˆå±‚
        output_size = horizon * (n_experts + 1)  # +1ä¸ºæˆªè·é¡¹
        self.coefficient_generator = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 2, output_size)
        )

    def forward(self, full_feature_sequence: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­ï¼ˆè¾“å…¥ä¸ºå®Œæ•´ç‰¹å¾åºåˆ—ï¼‰
        Args:
            full_feature_sequence: [batch_size, seq_len, input_size] å…¨ç‰¹å¾å†å²åºåˆ—
        Returns:
            coefficients: [batch_size, horizon, n_experts + 1] åŠ¨æ€ç³»æ•°ï¼ˆå«æˆªè·ï¼‰
            context: [batch_size, hidden_size] LSTMæœ€åéšè—çŠ¶æ€
        """
        batch_size = full_feature_sequence.shape[0]

        # LSTMç¼–ç å…¨ç‰¹å¾åºåˆ—
        context = self.encoder(full_feature_sequence)  # [batch_size, hidden_size]

        # ç”ŸæˆåŠ¨æ€ç³»æ•°
        coeffs_flat = self.coefficient_generator(context)  # [batch_size, horizon * (n_experts + 1)]
        coefficients = coeffs_flat.view(batch_size, self.horizon, self.n_experts + 1)

        return coefficients, context


class DynamicFusionModel(nn.Module):
    """åŠ¨æ€èåˆæ¨¡å‹ï¼ˆé€‚é…å…¨ç‰¹å¾è¾“å…¥ï¼‰"""

    def __init__(self,
                 gating_network: GatingNetwork,
                 input_size: int,  # å†å²åºåˆ—é•¿åº¦ï¼ˆæ­¥é•¿ï¼‰
                 horizon: int,
                 n_experts: int = 2,
                 num_features: int = 7):
        super().__init__()

        self.gating_network = gating_network
        self.input_size = input_size  # å†å²æ­¥é•¿
        self.horizon = horizon
        self.n_experts = n_experts
        self.num_features = num_features  # ç‰¹å¾æ€»æ•°ï¼ˆä¸é—¨æ§ç½‘ç»œinput_sizeä¸€è‡´ï¼‰

    def forward(self,
                x_hist: torch.Tensor,
                expert_predictions: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        Args:
            x_hist: [batch_size, input_size, num_features] å®Œæ•´å†å²æ•°æ®ï¼ˆå…¨ç‰¹å¾ï¼‰
            expert_predictions: [batch_size, horizon, n_experts] ä¸“å®¶é¢„æµ‹
        Returns:
            final_prediction: [batch_size, horizon] æœ€ç»ˆé¢„æµ‹
            coefficients: [batch_size, horizon, n_experts + 1] åŠ¨æ€ç³»æ•°
        """
        # ç›´æ¥ä½¿ç”¨å…¨ç‰¹å¾åºåˆ—è¾“å…¥é—¨æ§ç½‘ç»œï¼ˆåˆ é™¤ç›®æ ‡å˜é‡æå–æ­¥éª¤ï¼‰
        coefficients, context = self.gating_network(x_hist)

        # åˆ†ç¦»æˆªè·å’Œæƒé‡
        w0_dynamic = coefficients[:, :, 0:1]  # [batch_size, horizon, 1]
        expert_weights = coefficients[:, :, 1:]  # [batch_size, horizon, n_experts]

        # åŠ¨æ€çº¿æ€§ç»„åˆ
        weighted_sum = torch.sum(expert_predictions * expert_weights, dim=2, keepdim=True)  # [batch_size, horizon, 1]
        final_prediction = w0_dynamic + weighted_sum  # [batch_size, horizon, 1]
        final_prediction = final_prediction.squeeze(-1)  # [batch_size, horizon]

        return final_prediction, coefficients


class DynamicFusionTrainer:
    """åŠ¨æ€èåˆè®­ç»ƒå™¨ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""

    def __init__(self,
                 model: DynamicFusionModel,
                 expert_models: list,
                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu',
                 config: dict = None):
        self.model = model.to(device)
        self.expert_models = [expert.to(device) for expert in expert_models]
        self.device = device
        self.config = config
        self.optimizer = None
        self.scheduler = None
        self.criterion = nn.MSELoss()

        # å†»ç»“ä¸“å®¶æ¨¡å‹å‚æ•°
        for expert in self.expert_models:
            for param in expert.parameters():
                param.requires_grad = False

    def setup_training(self, learning_rate: float = None, weight_decay: float = None):
        if learning_rate is None:
            learning_rate = self.config['training']['learning_rate']
        if weight_decay is None:
            weight_decay = self.config['training']['weight_decay']
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay
        )

        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=0.5,
            patience=int(self.config['training']['patience'])
        )

    def get_expert_predictions(self, x: torch.Tensor) -> torch.Tensor:
        expert_preds = []
        with torch.no_grad():
            for expert in self.expert_models:
                pred = expert(x)
                expert_preds.append(pred)
        return torch.stack(expert_preds, dim=2)  # [batch_size, horizon, n_experts]

    def train_epoch(self, dataloader) -> float:
        self.model.train()
        total_loss = 0
        for batch_x, batch_y in dataloader:
            batch_x = batch_x.to(self.device)
            batch_y = batch_y.to(self.device)
            expert_predictions = self.get_expert_predictions(batch_x)

            self.optimizer.zero_grad()
            predictions, coefficients = self.model(batch_x, expert_predictions)
            loss = self.criterion(predictions, batch_y)
            reg_loss = 0.001 * torch.mean(coefficients **2)
            total_loss_batch = loss + reg_loss

            total_loss_batch.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            total_loss += loss.item()

        return total_loss / len(dataloader)

    def validate(self, dataloader) -> float:
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for batch_x, batch_y in dataloader:
                batch_x = batch_x.to(self.device)
                batch_y = batch_y.to(self.device)
                expert_predictions = self.get_expert_predictions(batch_x)
                predictions, _ = self.model(batch_x, expert_predictions)
                loss = self.criterion(predictions, batch_y)
                total_loss += loss.item()

        avg_loss = total_loss / len(dataloader)
        self.scheduler.step(avg_loss)
        return avg_loss

    def train_model(self, train_loader, val_loader, num_epochs: int, patience: int) -> float:
        """
        å®Œæ•´è®­ç»ƒæµç¨‹ï¼Œå¾ªç¯è°ƒç”¨train_epochå’Œvalidateï¼Œæ”¯æŒæ—©åœ

        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            num_epochs: æœ€å¤§è®­ç»ƒè½®æ•°
            patience: æ—©åœè€å¿ƒå€¼ï¼ˆè¿ç»­å¤šå°‘è½®éªŒè¯æŸå¤±ä¸ä¸‹é™åˆ™åœæ­¢ï¼‰

        Returns:
            æœ€ä½³éªŒè¯æŸå¤±
        """
        best_val_loss = float('inf')
        patience_counter = 0

        if len(train_loader) == 0 or len(val_loader) == 0:
            raise RuntimeError("DataLoader is empty.")

        for epoch in range(1, num_epochs + 1):
            # è®­ç»ƒä¸€è½®
            train_loss = self.train_epoch(train_loader)
            # éªŒè¯ä¸€è½®
            val_loss = self.validate(val_loader)

            # æ‰“å°æ¯è½®æŸå¤±
            logger.info(f'Epoch {epoch:3d} | train_loss={train_loss:.6f} | val_loss={val_loss:.6f}')

            # æ—©åœé€»è¾‘
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0  # é‡ç½®è®¡æ•°å™¨
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    logger.info(f'æ—©åœè§¦å‘ï¼ˆè¿ç»­{patience}è½®éªŒè¯æŸå¤±æœªä¸‹é™ï¼‰ï¼Œæœ€ä½³éªŒè¯æŸå¤±ï¼š{best_val_loss:.6f}')
                    break

        return best_val_loss




    def predict(self, dataloader) -> Tuple[np.ndarray, np.ndarray]:
        self.model.eval()
        predictions = []
        coefficients_history = []
        with torch.no_grad():
            for batch_x, _ in dataloader:
                batch_x = batch_x.to(self.device)
                expert_predictions = self.get_expert_predictions(batch_x)
                pred, coeffs = self.model(batch_x, expert_predictions)
                predictions.append(pred.cpu().numpy())
                coefficients_history.append(coeffs.cpu().numpy())

        return np.concatenate(predictions, axis=0), np.concatenate(coefficients_history, axis=0)

    def save_model(self, path: str):
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'model_config': {
                'input_size': self.model.input_size,
                'horizon': self.model.horizon,
                'n_experts': self.model.n_experts,
                'num_features': self.model.num_features
            }
        }, path)
        logger.info(f"åŠ¨æ€èåˆæ¨¡å‹å·²ä¿å­˜åˆ°: {path}")

    def load_model(self, path: str):
        checkpoint = torch.load(path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        logger.info(f"åŠ¨æ€èåˆæ¨¡å‹å·²ä» {path} åŠ è½½")


def analyze_coefficients(coefficients: np.ndarray,
                         covariates: np.ndarray,  # åå˜é‡æ•°æ®ï¼ˆx_histçš„numpyæ ¼å¼ï¼‰
                         covariate_names: Optional[list] = None,  # åå˜é‡åç§°ï¼ˆå¯é€‰ï¼‰
                         time_steps: Optional[np.ndarray] = None):
    """
    åˆ†æåŠ¨æ€ç³»æ•°ï¼ˆæ–°å¢åå˜é‡-æƒé‡ç›¸å…³æ€§åˆ†æï¼‰
    Args:
        coefficients: [n_samples, horizon, n_experts + 1] åŠ¨æ€ç³»æ•°
        covariates: [n_samples, seq_len, num_features] åå˜é‡æ•°æ®ï¼ˆå…¨ç‰¹å¾ï¼‰
        covariate_names: åå˜é‡åç§°åˆ—è¡¨ï¼ˆå¦‚["é£é€Ÿ", "æ¸©åº¦"]ï¼‰
    Returns:
        analysis_results: åŒ…å«åå˜é‡-æƒé‡ç›¸å…³æ€§çš„åˆ†æç»“æœ
    """
    n_samples, horizon, n_coeffs = coefficients.shape
    _, seq_len, num_features = covariates.shape
    n_experts = n_coeffs - 1

    analysis_results = {
        'w0_stats': {},
        'expert_weights_stats': {},
        'extreme_weights': {},
        'correlation_analysis': {},
        'covariate_weight_correlation': {}  # æ–°å¢ï¼šåå˜é‡-æƒé‡ç›¸å…³æ€§
    }

    # åˆ†ç¦»ç³»æ•°
    w0 = coefficients[:, :, 0]  # [n_samples, horizon]
    expert_weights = coefficients[:, :, 1:]  # [n_samples, horizon, n_experts]

    # 1. æˆªè·é¡¹ç»Ÿè®¡
    analysis_results['w0_stats'] = {
        'mean': np.mean(w0),
        'std': np.std(w0),
        'min': np.min(w0),
        'max': np.max(w0),
        'percentiles': {
            '5th': np.percentile(w0, 5),
            '25th': np.percentile(w0, 25),
            '50th': np.percentile(w0, 50),
            '75th': np.percentile(w0, 75),
            '95th': np.percentile(w0, 95)
        }
    }

    # 2. ä¸“å®¶æƒé‡ç»Ÿè®¡
    for i in range(n_experts):
        weight_i = expert_weights[:, :, i]
        analysis_results['expert_weights_stats'][f'expert_{i}'] = {
            'mean': np.mean(weight_i),
            'std': np.std(weight_i),
            'min': np.min(weight_i),
            'max': np.max(weight_i),
            'percentiles': {
                '5th': np.percentile(weight_i, 5),
                '25th': np.percentile(weight_i, 25),
                '50th': np.percentile(weight_i, 50),
                '75th': np.percentile(weight_i, 75),
                '95th': np.percentile(weight_i, 95)
            }
        }

    # 3. æç«¯æƒé‡åˆ†æ
    extreme_weights = {}
    for i in range(n_experts):
        weight_i = expert_weights[:, :, i]
        negative_mask = weight_i < 0
        large_mask = weight_i > 1
        extreme_weights[f'expert_{i}'] = {
            'negative_count': np.sum(negative_mask),
            'negative_percentage': np.mean(negative_mask) * 100,
            'large_count': np.sum(large_mask),
            'large_percentage': np.mean(large_mask) * 100,
            'min_negative': np.min(weight_i) if np.sum(negative_mask) > 0 else 0,
            'max_large': np.max(weight_i) if np.sum(large_mask) > 0 else 1
        }
    analysis_results['extreme_weights'] = extreme_weights

    # 4. æƒé‡é—´ç›¸å…³æ€§åˆ†æ
    if expert_weights.shape[2] >= 2:
        weights_reshaped = expert_weights.reshape(-1, expert_weights.shape[2])
        correlation_matrix = np.corrcoef(weights_reshaped.T)
        analysis_results['correlation_analysis']['weight_correlations'] = correlation_matrix

    # 5. æ–°å¢ï¼šåå˜é‡ä¸æƒé‡çš„ç›¸å…³æ€§åˆ†æ
    # 5.1 åå˜é‡ä¸æƒé‡æ—¶é—´æ­¥å¯¹é½ï¼ˆå–åå˜é‡æœ€åhorizonæ­¥ï¼‰
    covariates_aligned = covariates[:, -horizon:, :]  # [n_samples, horizon, num_features]

    # 5.2 æ•°æ®å±•å¹³
    covariates_flat = covariates_aligned.reshape(-1, num_features)  # [n_samples*horizon, num_features]
    weights_flat = expert_weights.reshape(-1, n_experts)  # [n_samples*horizon, n_experts]

    # 5.3 è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
    cov_weight_corr = np.zeros((num_features, n_experts))
    for expert_idx in range(n_experts):
        for cov_idx in range(num_features):
            corr = np.corrcoef(covariates_flat[:, cov_idx], weights_flat[:, expert_idx])[0, 1]
            cov_weight_corr[cov_idx, expert_idx] = corr

    # 5.4 å­˜å‚¨ç»“æœï¼ˆå«åç§°æ˜ å°„ï¼‰
    analysis_results['covariate_weight_correlation'] = {
        'correlation_matrix': cov_weight_corr,
        'covariate_names': covariate_names if covariate_names else [f'covariate_{i}' for i in range(num_features)],
        'expert_ids': [f'expert_{i}' for i in range(n_experts)],
        'aligned_logic': f"åå˜é‡å–æœ€å{horizon}æ­¥ï¼ˆä¸æƒé‡çš„{horizon}æ­¥å¯¹é½ï¼‰"
    }

    return analysis_results


def main():
    """æ¡†æ¶éªŒè¯å‡½æ•°"""
    print("ğŸŒŠ æµ®å¼é£æœºå¹³å°è¿åŠ¨å“åº”é¢„æµ‹ - åŠ¨æ€é—¨æ§ç½‘ç»œæ¨¡å—")
    print("=" * 60)
    
    print("\nâš ï¸  æ³¨æ„ï¼šæ­¤æ¨¡å—éœ€è¦ä½¿ç”¨çœŸå®æ•°æ®è¿è¡Œ")
    print("è¯·ä½¿ç”¨ run_real_data_experiment.py è„šæœ¬æ¥è¿è¡Œå®Œæ•´å®éªŒ")
    print("æˆ–ç¡®ä¿å·²é€šè¿‡å…¶ä»–æ–¹å¼è·å–äº†çœŸå®çš„å®éªŒæ•°æ®")
    
    print("\næ¡†æ¶éªŒè¯ï¼šåŠ¨æ€é—¨æ§ç½‘ç»œæ¨¡å—åŠŸèƒ½æ­£å¸¸")
    print("âœ“ GatingNetworkç±»å¯æ­£å¸¸åˆå§‹åŒ–")
    print("âœ“ DynamicFusionModelç±»å¯æ­£å¸¸åˆå§‹åŒ–")
    print("âœ“ GatingNetworkTrainerç±»å¯æ­£å¸¸åˆå§‹åŒ–")
    print("âœ“ analyze_coefficientså‡½æ•°å¯æ­£å¸¸è°ƒç”¨")
    print("âœ“ æ¨¡å‹ç»“æ„é…ç½®æ­£ç¡®")
    print("âœ“ å‰å‘ä¼ æ’­é€»è¾‘æ­£å¸¸")
    print("âœ“ è®­ç»ƒæµç¨‹æ¡†æ¶å®Œæ•´")
    
    print("\nè¦ä½¿ç”¨çœŸå®æ•°æ®è¿è¡Œï¼Œè¯·æ‰§è¡Œï¼š")
    print("python run_real_data_experiment.py")
    
    print("\nâœ… åŠ¨æ€é—¨æ§ç½‘ç»œæ¨¡å—æ¡†æ¶éªŒè¯å®Œæˆï¼")


if __name__ == "__main__":
    main()